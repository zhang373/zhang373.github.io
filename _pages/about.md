---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Nice to meet you! I am Wenshuo ZHANG (å¼ æ–‡ç¡•), currently a Ph.D. student in HKUST VisLab, at the Department of Computer Science and Engineering of the Hong Kong University of Science and Technology (HKUST), supervised by Prof. Huamin Qu and working with Dr.Linping Yuan.       

Before joining HKUST, I obtained my B.S. degree in Automation, the Department of Electronic and Information Engineering, Xi'an Jiaotong University, FYP supervised by Prof. Lei CHEN and Dr. Zhao CHEN at HKUST Guangzhou in 2024. I also obtained a dual Bachelor's degree in Accounting (ACCA Track), the Management School, Xi'an Jiaotong University, FYP supervised by Prof. Hong ZHAO in 2024. During my UG study, I went to the Department of Electrical and Electronic Engineering at the University of Hong Kong as a government-sponsored exchange student and worked with Prof. Xiaojuan QI there.    

My research interest lies in **Human LLM Alignment in Multi-round Dialog / Agentic System**, including (1) accessing LLM's internal pattern to regularize users' behaviours to meet LLM input needs, (2) learning and modeling users' behaviours to do post-training on LLM to overcome users' shortages, and (3) data augmentation and evaluation to support the bidirectional alignment. If you are interested in cooperating with me, feel free to drop me an email. Let's go together to **Make the Impossible Possible and the Possible Easy**. 


# ğŸ”¥ News
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ Two papers accepted in UIST 2025, Thanks to my coauthors!
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ One cooperation paper and one first-author paper submitted to UIST 2025, Thanks to my coauthors!
- *2024.10*: &nbsp;ğŸ‰ğŸ‰ One cooperation paper submitted to CSCW 2025, Thanks to my coauthors! Resubmitted to CSCW 2026 as short paper.
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ We get Prof. Ganâ€™s follwing up $1m Grant! Congratulations wenshuo(yeah this is me), teammates(jindu, haobo) and PI(Dr.Linping YUAN and Dr.Jun HAN)!
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ I went to HKUST as a year one Ph.D. student. Hope to see you guys!
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ I got my B.S. degree in Automation, the Department of Electronic and Information Engineering, XJTU!
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ I got my B.S. degree in Accounting (ACCA Track), the Management School, XJTU!
- *2023.09*: &nbsp;ğŸ‰ğŸ‰ I start my journey in HKUST(GZ) as a research intern!
- *2023.02*: &nbsp;ğŸ‰ğŸ‰ I start my journey in HKU as an exchange student!

# ğŸ“ Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UIST 2025</div><img src='images/NeuroSync.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://arxiv.org/abs/2508.02823)

**Wenshuo Zhang**, Leixian Shen, Shuchang Xu, Jindu Wang, Jian Zhao, Huamin Qu, Linping Yuan

[**Website**](https://zhang373.github.io/NeuroSync_Web/) 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UIST 2025</div><img src='images/BranchExplore.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Branch Explorer: Leveraging Branching Narratives to Support Interactive 360Â° Video Viewing for Blind and Low Vision Users](https://arxiv.org/abs/2507.09959)

Shuchang Xu, Xiaofu Jin, **Wenshuo Zhang**, Huamin Qu, Yukang Yan

[**Video**](https://youtu.be/AW8jinSEehI) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>


# ğŸ‘¨â€ğŸ­ Projects
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AoE Digital Twin</div><img src='images/AoE.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Guangdong-Hong Kong-Macao Great Bay Area Regional Earth System Digital Twin Project](https://mp.weixin.qq.com/s/ghdBcgAd1y-rqB4GLlanWQ)

- 60 million HKD form RGC@HK, 1.4 million for us
- Responsible for part "Neuro Network and Distillation Based Ocean Data Compression for Visualization Acceleration". Developed a machine learning-based compression framework to enable real-time, interactive VR visualization of large-scale scientific data. This innovation addressed significant latency issues by compressing daily data files from over 6 GB to a highly efficient 6.75 MB model, reducing data processing and rendering time to just 0.75 seconds on Nvidia 3070.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Digital Campus of HKUST</div><img src='images/DigitalCampus.png' alt="sym" width="100%" height="60%"></div></div>
<div class='paper-box-text' markdown="1">

[The Hong Kong University of Science and Technology Digital Twin Smart Campus](https://mp.weixin.qq.com/s/ghdBcgAd1y-rqB4GLlanWQ)

- The project aims to create a comprehensive digital twin platform that integrates diverse data on campus, aiming to enhance the convenience and interactivity of campus life for students and faculty. The project monitors crowd dynamics and facility status in real time while ensuring user privacy through core features such as augmented reality exploration, gamified sustainability, social interaction and smart navigation. The platform integrates cafeteria information, course scheduling, activity information, social assistance, and environmental data monitoring, and provides data support for campus management through mobile apps, VR, and large-screen displays to create an intelligent and efficient learning and living environment.

</div>
</div>


# ğŸ– Selected Honors and Awards
- *2024.08* Post Graduate Studentship(PGS), the Hong Kong University of Science and Technology!
- *2020 - 2024* Excellent Student Cadre in 2021, Outstanding Student in 2022 and 2023, Outstanding Graduate Student in 2024. All in Xi'an Jiaotong University!
- *2023.05* Fung Scholar and Fung Scholarship (Together with World Level University Students like MIT), the University of Hong Kong!
- *2023.05* First Prize of National University Student Mathematical Modeling Competition in Shaanxi Competition Region, Xi'an Jiaotong University!
- *2021.09* Jianbing Alumni Inspirational Scholarship (Top 2 out of over 300 people), Xi'an Jiaotong University!
  
# ğŸ“– Educations
- *2024.08 - now*, Ph.D. Student, CSE Department, the Hong Kong University of Science and Technology. 
- *2021.09 - 2024.07*, B.S. in Engineering, Automation, Faculty of Electronics and Information Engineering, Xi'an Jiaotong University.
- *2020.10 - 2024.05*, Dual B.S. in Manangement, Accounting(ACCA Track), School of Management, Xi'an Jiaotong University.
- *2023.02 - 2023.06*, Funded Exchange Student, Department of Electrical and Electronic Engineering, the University of Hong Kong.
- *2020.09 - 2021.07*, Computational Finance, School of Economics and Finance, Xi'an Jiaotong University.

# ğŸ’¬ Invited Talks-
- *2025.10*, Oral session in UIST 2025, [NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://hkustconnect-my.sharepoint.com/:p:/g/personal/wzhangeb_connect_ust_hk/ER6Km4ctdbhHlYRitqsnVi0BMMVJjw1CzoXYasevbiEL2w?e=tFuKBf). 
- *2025.07*, Guest Talk on Cutting-edge Paper Sharing session in ChinaVis 2025, [NeuroSync: How to do better intent-aware coding by chatting with LLM](https://hkustconnect-my.sharepoint.com/:p:/g/personal/wzhangeb_connect_ust_hk/ER6Km4ctdbhHlYRitqsnVi0BMMVJjw1CzoXYasevbiEL2w?e=tFuKBf).
- *2025.05*, Sharing in EMIA 6500K, [ML Based Large-Scale Scientific Data Compression for Interactive VR Game Creation](docs/SciVis_data_compression_WenshuoZHANG.pdf).
- *2025.03*, Sharing in EMIA 6500K, Vislab and COMP 6411 C, [Image Editing with New Content Created by Interactive Generation Model](docs/Visual_editing_wenshuo.pdf).
- *2024.08 - now*, you can get my reading notes in Chinese from [Wenshuo's Reading Posts](https://www.zhihu.com/people/ha-ha-ha-67-6/posts)
- *2023.11*, Share in Med Data Lab at HKUSTGZ about [Diffusion Model](https://github.com/zhang373/zhang373.github.io/blob/main/docs/Diffusion_wenshuo.pdf). Updated [version](https://github.com/zhang373/zhang373.github.io/blob/main/docs/Diffusion_updataed.pdf) for VisLab sharing in 2024.12.10

# ğŸ’» Internships
- *2025.11 - now*, Intern, AI for Science Project, Solution Architecture Team, Nvidia, Science Park, Hong Kong.
- *2023.09 - 2024.02*, Funded Research Intern, Data Science and Analyze, Information Hub, the Hong Kong University of Science and Technology Guangzhou.

# ğŸ’¬ Academic and Teaching Services
- **2025** Teaching Assistant in COMP 6411D: Data Visualization, HKUST 
- **2025** Teaching Assistant in COMP 1029C: C Programming Bridging Course, HKUST 
- **2025** Reviewer for CHI 2025 Late Breaking Work

You can find my CV [here](docs/CV_WenshuoZhang_HKUST_CSE_PhD_Intern.pdf), website and CV updated in 2025.07

